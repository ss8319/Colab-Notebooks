{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjm68/xkEykrgGSwFe82S8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ss8319/Colab-Notebooks/blob/main/VocabTransfer_openNMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Tokenize parent and child corpus\n",
        "2.Build parent model\n",
        "3.Build child model"
      ],
      "metadata": {
        "id": "dsDMBK0Sfp0R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jLqQcrkfdlF",
        "outputId": "c03d906f-40e6-4e64-d796-e001e7321dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Confirm GPU availability\n",
        "# Runtime>Change runtime type\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers\n",
        "! pip install simpletransformers\n",
        "! pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jqjrxqNbfi7o",
        "outputId": "e7cde670-2e81-4edc-c3df-27ea2cf8b1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 37.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting simpletransformers\n",
            "  Downloading simpletransformers-0.63.7-py3-none-any.whl (249 kB)\n",
            "\u001b[K     |████████████████████████████████| 249 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting streamlit\n",
            "  Downloading streamlit-1.10.0-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.0.2)\n",
            "Collecting wandb>=0.10.32\n",
            "  Downloading wandb-0.12.18-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 41.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2.8.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
            "\u001b[K     |████████████████████████████████| 362 kB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.3.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2022.6.2)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.21.6)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (4.20.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (0.12.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (3.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (4.11.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (0.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers>=4.6.0->simpletransformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.6.0->simpletransformers) (3.0.9)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (3.17.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (7.1.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers) (57.4.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (2022.5.18.1)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (0.70.13)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (6.0.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 12.5 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (0.3.5.1)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 44.8 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (21.4.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 44.6 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 51.8 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers) (2.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.6.0->simpletransformers) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->simpletransformers) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->simpletransformers) (2.8.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->simpletransformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->simpletransformers) (3.1.0)\n",
            "Collecting watchdog\n",
            "  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (7.1.2)\n",
            "Collecting pympler>=0.9\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting pydeck>=0.1.dev5\n",
            "  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 27.9 MB/s \n",
            "\u001b[?25hCollecting blinker\n",
            "  Downloading blinker-1.4.tar.gz (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 38.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (4.2.0)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (5.1.1)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (2.13.0)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (4.2.4)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (1.5.1)\n",
            "Collecting rich\n",
            "  Downloading rich-12.4.4-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 45.4 MB/s \n",
            "\u001b[?25hCollecting validators\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (2.11.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.11.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (4.3.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (5.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (0.18.1)\n",
            "Collecting ipykernel>=5.1.2\n",
            "  Downloading ipykernel-6.15.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 43.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (5.1.1)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (7.7.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.1.3)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.5.5)\n",
            "Collecting jupyter-client>=6.1.12\n",
            "  Downloading jupyter_client-7.3.4-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.2 MB/s \n",
            "\u001b[?25hCollecting ipython>=7.23.1\n",
            "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 37.7 MB/s \n",
            "\u001b[?25hCollecting tornado>=5.0\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[K     |████████████████████████████████| 428 kB 40.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.0.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.29-py3-none-any.whl (381 kB)\n",
            "\u001b[K     |████████████████████████████████| 381 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.18.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.8.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.6.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.1.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.4.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit->simpletransformers) (2.0.1)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.10.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.15.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.13.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.6.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.0.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.46.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers) (0.37.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (3.2.0)\n",
            "Building wheels for collected packages: pathtools, seqeval, blinker, validators\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=5220b2dc78e04d7dea6a3fcff9bb6e5ec653e3fa5fcb651c67425e4bb2776bde\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=b75b6cfedf9b958d2001c17bf9ac935cd85b33d2d794ce236c0a010d030d9f5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13478 sha256=b01a6906b4e72ce32c59b2b71ca5613178901bbcbbe63824dc7299840486f0cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=ee073a454681a7a70b685aeb7e3a8ba4717cb21200ea55e63e014461d29575d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n",
            "Successfully built pathtools seqeval blinker validators\n",
            "Installing collected packages: tornado, prompt-toolkit, jupyter-client, ipython, ipykernel, urllib3, multidict, frozenlist, yarl, smmap, asynctest, async-timeout, aiosignal, gitdb, fsspec, commonmark, aiohttp, xxhash, watchdog, validators, toml, shortuuid, setproctitle, sentry-sdk, rich, responses, pympler, pydeck, pathtools, GitPython, docker-pycreds, blinker, wandb, streamlit, seqeval, sentencepiece, datasets, simpletransformers\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.6.4 requires traitlets>=5.2.2, but you have traitlets 5.1.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.27 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 blinker-1.4 commonmark-0.9.1 datasets-2.3.2 docker-pycreds-0.4.0 frozenlist-1.3.0 fsspec-2022.5.0 gitdb-4.0.9 ipykernel-6.15.0 ipython-7.34.0 jupyter-client-7.3.4 multidict-6.0.2 pathtools-0.1.2 prompt-toolkit-3.0.29 pydeck-0.7.1 pympler-1.0.1 responses-0.18.0 rich-12.4.4 sentencepiece-0.1.96 sentry-sdk-1.5.12 seqeval-1.2.2 setproctitle-1.2.3 shortuuid-1.0.9 simpletransformers-0.63.7 smmap-5.0.0 streamlit-1.10.0 toml-0.10.2 tornado-6.1 urllib3-1.25.11 validators-0.20.0 wandb-0.12.18 watchdog-2.1.9 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "prompt_toolkit",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExHBhavpfkKS",
        "outputId": "3caeabda-4184-41fc-e33e-ffca944f702e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxWr8nYgf41i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile step1.py\n",
        "##### SCRIPT STARTS HERE #####\n",
        "#!usr/bin/bash python\n",
        "#step 1 - Create SentencePiece vocabulary for dataset\n",
        "import sentencepiece as spm\n",
        "import argparse\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--dataset\", type=str, required=True)\n",
        "    parser.add_argument(\"--prefix\", type=str, required=True)\n",
        "    parser.add_argument(\"--vocab_size\", type=int, required=True)\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "def create_vocab(dataset_pth, prefix, vocab_size):\n",
        "    \"\"\"output: {prefix}.model {prefix}.vocab\"\"\"\n",
        "    print(dataset_pth, prefix, vocab_size)\n",
        "    spm.SentencePieceTrainer.train(\n",
        "        f\"--input={dataset_pth} --model_prefix={prefix}  --vocab_size={vocab_size} \\\n",
        "        --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3 \\\n",
        "        --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS] \\\n",
        "        --user_defined_symbols=[CLS],[SEP],[MASK]\"\n",
        "    )\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "    create_vocab(args.dataset, args.prefix, args.vocab_size)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cti1iq87f5QO",
        "outputId": "53b0abdc-5237-45c4-97bd-2daca0fc112a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing step1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pam6JaXORMtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29bf92b2-e6ea-4390-8e24-02a7fa5ef659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/Shareddrives/Gutenberg/MT/scripture/oro-HARX_2022_01_29.txt oro-HARX 8000\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/content/gdrive/Shareddrives/Gutenberg/MT/scripture/oro-HARX_2022_01_29.txt --model_prefix=oro-HARX  --vocab_size=8000         --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3         --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]         --user_defined_symbols=[CLS],[SEP],[MASK]\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /content/gdrive/Shareddrives/Gutenberg/MT/scripture/oro-HARX_2022_01_29.txt\n",
            "  input_format: \n",
            "  model_prefix: oro-HARX\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 8000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  user_defined_symbols: [CLS]\n",
            "  user_defined_symbols: [SEP]\n",
            "  user_defined_symbols: [MASK]\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 1\n",
            "  bos_id: 2\n",
            "  eos_id: 3\n",
            "  pad_id: 0\n",
            "  unk_piece: [UNK]\n",
            "  bos_piece: [BOS]\n",
            "  eos_piece: [EOS]\n",
            "  pad_piece: [PAD]\n",
            "  unk_surface:  ⁇ \n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: /content/gdrive/Shareddrives/Gutenberg/MT/scripture/oro-HARX_2022_01_29.txt\n",
            "trainer_interface.cc(385) LOG(INFO) Loaded all 12652 sentences\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [PAD]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [UNK]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [BOS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [EOS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [CLS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [SEP]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [MASK]\n",
            "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(466) LOG(INFO) all chars count=1639409\n",
            "trainer_interface.cc(477) LOG(INFO) Done: 99.9527% characters are covered.\n",
            "trainer_interface.cc(487) LOG(INFO) Alphabet size=56\n",
            "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999527\n",
            "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 12652 sentences.\n",
            "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
            "unigram_model_trainer.cc(194) LOG(INFO) Initialized 28510 seed sentencepieces\n",
            "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 12652\n",
            "trainer_interface.cc(537) LOG(INFO) Done! 20051\n",
            "unigram_model_trainer.cc(489) LOG(INFO) Using 20051 sentences for EM training\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10719 obj=10.4117 num_tokens=41309 num_tokens/piece=3.85381\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=9045 obj=8.25562 num_tokens=41421 num_tokens/piece=4.57944\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8495 obj=8.1993 num_tokens=41487 num_tokens/piece=4.8837\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8440 obj=8.19005 num_tokens=41541 num_tokens/piece=4.92192\n",
            "trainer_interface.cc(615) LOG(INFO) Saving model: oro-HARX.model\n",
            "trainer_interface.cc(626) LOG(INFO) Saving vocabs: oro-HARX.vocab\n"
          ]
        }
      ],
      "source": [
        "!python3 step1.py --dataset=/content/gdrive/Shareddrives/Gutenberg/MT/scripture/oro-HARX_2022_01_29.txt --prefix=oro-HARX --vocab_size=8000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIpDrFMnXjSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4264ae98-a660-4349-ba2c-545b07ff5fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/Shareddrives/Gutenberg/MT/scripture/ko-BTKX_2021_10_14.txt ko-BTKX 8000\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/content/gdrive/Shareddrives/Gutenberg/MT/scripture/ko-BTKX_2021_10_14.txt --model_prefix=ko-BTKX  --vocab_size=8000         --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3         --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]         --user_defined_symbols=[CLS],[SEP],[MASK]\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /content/gdrive/Shareddrives/Gutenberg/MT/scripture/ko-BTKX_2021_10_14.txt\n",
            "  input_format: \n",
            "  model_prefix: ko-BTKX\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 8000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  user_defined_symbols: [CLS]\n",
            "  user_defined_symbols: [SEP]\n",
            "  user_defined_symbols: [MASK]\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 1\n",
            "  bos_id: 2\n",
            "  eos_id: 3\n",
            "  pad_id: 0\n",
            "  unk_piece: [UNK]\n",
            "  bos_piece: [BOS]\n",
            "  eos_piece: [EOS]\n",
            "  pad_piece: [PAD]\n",
            "  unk_surface:  ⁇ \n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: /content/gdrive/Shareddrives/Gutenberg/MT/scripture/ko-BTKX_2021_10_14.txt\n",
            "trainer_interface.cc(385) LOG(INFO) Loaded all 11173 sentences\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [PAD]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [UNK]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [BOS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [EOS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [CLS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [SEP]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [MASK]\n",
            "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(466) LOG(INFO) all chars count=794863\n",
            "trainer_interface.cc(477) LOG(INFO) Done: 99.9502% characters are covered.\n",
            "trainer_interface.cc(487) LOG(INFO) Alphabet size=1013\n",
            "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999502\n",
            "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 11173 sentences.\n",
            "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
            "unigram_model_trainer.cc(194) LOG(INFO) Initialized 27975 seed sentencepieces\n",
            "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 11173\n",
            "trainer_interface.cc(537) LOG(INFO) Done! 36841\n",
            "unigram_model_trainer.cc(489) LOG(INFO) Using 36841 sentences for EM training\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=15569 obj=12.9105 num_tokens=82415 num_tokens/piece=5.29353\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=13505 obj=11.6418 num_tokens=82613 num_tokens/piece=6.11722\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10124 obj=11.7895 num_tokens=86695 num_tokens/piece=8.56331\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=10121 obj=11.7393 num_tokens=86708 num_tokens/piece=8.56714\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8800 obj=11.9028 num_tokens=89514 num_tokens/piece=10.172\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8800 obj=11.881 num_tokens=89523 num_tokens/piece=10.1731\n",
            "trainer_interface.cc(615) LOG(INFO) Saving model: ko-BTKX.model\n",
            "trainer_interface.cc(626) LOG(INFO) Saving vocabs: ko-BTKX.vocab\n"
          ]
        }
      ],
      "source": [
        "!python3 step1.py --dataset=/content/gdrive/Shareddrives/Gutenberg/MT/scripture/ko-BTKX_2021_10_14.txt --prefix=ko-BTKX --vocab_size=8000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0qkaHZYPggX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455a4a0e-5d31-40f3-e891-9a5672b336c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/Shareddrives/Gutenberg/MT/corpora/en-CCMatrix_en_ko_clean_5k.txt en-CCMatrix 5000\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/content/gdrive/Shareddrives/Gutenberg/MT/corpora/en-CCMatrix_en_ko_clean_5k.txt --model_prefix=en-CCMatrix  --vocab_size=5000         --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3         --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]         --user_defined_symbols=[CLS],[SEP],[MASK]\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /content/gdrive/Shareddrives/Gutenberg/MT/corpora/en-CCMatrix_en_ko_clean_5k.txt\n",
            "  input_format: \n",
            "  model_prefix: en-CCMatrix\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 5000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  user_defined_symbols: [CLS]\n",
            "  user_defined_symbols: [SEP]\n",
            "  user_defined_symbols: [MASK]\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 1\n",
            "  bos_id: 2\n",
            "  eos_id: 3\n",
            "  pad_id: 0\n",
            "  unk_piece: [UNK]\n",
            "  bos_piece: [BOS]\n",
            "  eos_piece: [EOS]\n",
            "  pad_piece: [PAD]\n",
            "  unk_surface:  ⁇ \n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: /content/gdrive/Shareddrives/Gutenberg/MT/corpora/en-CCMatrix_en_ko_clean_5k.txt\n",
            "trainer_interface.cc(385) LOG(INFO) Loaded all 5000 sentences\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [PAD]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [UNK]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [BOS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [EOS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [CLS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [SEP]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [MASK]\n",
            "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(466) LOG(INFO) all chars count=292747\n",
            "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
            "trainer_interface.cc(487) LOG(INFO) Alphabet size=81\n",
            "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
            "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 5000 sentences.\n",
            "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
            "unigram_model_trainer.cc(194) LOG(INFO) Initialized 15318 seed sentencepieces\n",
            "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 5000\n",
            "trainer_interface.cc(537) LOG(INFO) Done! 10130\n",
            "unigram_model_trainer.cc(489) LOG(INFO) Using 10130 sentences for EM training\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=6076 obj=10.9314 num_tokens=20920 num_tokens/piece=3.44305\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=5346 obj=9.096 num_tokens=21049 num_tokens/piece=3.93734\n",
            "trainer_interface.cc(615) LOG(INFO) Saving model: en-CCMatrix.model\n",
            "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en-CCMatrix.vocab\n"
          ]
        }
      ],
      "source": [
        "!python3 step1.py --dataset=/content/gdrive/Shareddrives/Gutenberg/MT/corpora/en-CCMatrix_en_ko_clean_5k.txt --prefix=en-CCMatrix --vocab_size=5000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 step1.py --dataset=/content/gdrive/Shareddrives/Gutenberg/MT/corpora/ko-CCMatrix_en_ko_clean_5k.txt --prefix=ko-CCMatrix --vocab_size=5000"
      ],
      "metadata": {
        "id": "EVQqz-XWv5WQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9062cf9-12ee-4a7f-8e17-adc576acdf2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/Shareddrives/Gutenberg/MT/corpora/ko-CCMatrix_en_ko_clean_5k.txt ko-CCMatrix 5000\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/content/gdrive/Shareddrives/Gutenberg/MT/corpora/ko-CCMatrix_en_ko_clean_5k.txt --model_prefix=ko-CCMatrix  --vocab_size=5000         --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3         --pad_piece=[PAD] --unk_piece=[UNK] --bos_piece=[BOS] --eos_piece=[EOS]         --user_defined_symbols=[CLS],[SEP],[MASK]\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /content/gdrive/Shareddrives/Gutenberg/MT/corpora/ko-CCMatrix_en_ko_clean_5k.txt\n",
            "  input_format: \n",
            "  model_prefix: ko-CCMatrix\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 5000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  user_defined_symbols: [CLS]\n",
            "  user_defined_symbols: [SEP]\n",
            "  user_defined_symbols: [MASK]\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 1\n",
            "  bos_id: 2\n",
            "  eos_id: 3\n",
            "  pad_id: 0\n",
            "  unk_piece: [UNK]\n",
            "  bos_piece: [BOS]\n",
            "  eos_piece: [EOS]\n",
            "  pad_piece: [PAD]\n",
            "  unk_surface:  ⁇ \n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: /content/gdrive/Shareddrives/Gutenberg/MT/corpora/ko-CCMatrix_en_ko_clean_5k.txt\n",
            "trainer_interface.cc(385) LOG(INFO) Loaded all 5000 sentences\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [PAD]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [UNK]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [BOS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [EOS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [CLS]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [SEP]\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [MASK]\n",
            "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(466) LOG(INFO) all chars count=180821\n",
            "trainer_interface.cc(477) LOG(INFO) Done: 99.9502% characters are covered.\n",
            "trainer_interface.cc(487) LOG(INFO) Alphabet size=1029\n",
            "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999502\n",
            "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 5000 sentences.\n",
            "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
            "unigram_model_trainer.cc(194) LOG(INFO) Initialized 11985 seed sentencepieces\n",
            "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 5000\n",
            "trainer_interface.cc(537) LOG(INFO) Done! 15070\n",
            "unigram_model_trainer.cc(489) LOG(INFO) Using 15070 sentences for EM training\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=7282 obj=13.3927 num_tokens=33849 num_tokens/piece=4.64831\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=6606 obj=12.3953 num_tokens=33974 num_tokens/piece=5.1429\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=5498 obj=12.6928 num_tokens=35286 num_tokens/piece=6.41797\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=5484 obj=12.6467 num_tokens=35302 num_tokens/piece=6.43727\n",
            "trainer_interface.cc(615) LOG(INFO) Saving model: ko-CCMatrix.model\n",
            "trainer_interface.cc(626) LOG(INFO) Saving vocabs: ko-CCMatrix.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install sacrebleu\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sacrebleu\n",
        "\n",
        "# Tell the SIL NLP tools where to find the Gutenberg resources\n",
        "os.environ['SIL_NLP_DATA_PATH'] = \"/content/gdrive/Shareddrives/Gutenberg\""
      ],
      "metadata": {
        "id": "SaeJMBIjgNHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uncomment to prepare df for trg->src also\n",
        "import os\n",
        "import pandas\n",
        "def prepare_translation_datasets(data_path, src_lang, src, trg_lang, trg, test_size):\n",
        "    src_text = []\n",
        "    trg_text = []\n",
        "    with open(os.path.join(data_path, src), \"r\", encoding=\"utf-8\") as s, \\\n",
        "         open(os.path.join(data_path, trg), \"r\", encoding=\"utf-8\") as t:\n",
        "        for src_line, trg_line in zip(s, t):\n",
        "            src_line = src_line.strip()\n",
        "            trg_line = trg_line.strip()\n",
        "            if len(src_line) == 0 or len(trg_line) == 0:\n",
        "                continue\n",
        "            src_text.append(src_line)\n",
        "            trg_text.append(trg_line)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(src_text, trg_text, test_size=test_size)\n",
        "\n",
        "\n",
        "    data = []\n",
        "    for src, trg in zip(X_train, y_train):\n",
        "        data.append([f\"translate {src_lang} to {trg_lang}\", src, trg])\n",
        "        #data.append([f\"translate {trg_lang} to {src_lang}\", trg, src])\n",
        "\n",
        "    train_df = pd.DataFrame(data, columns=[\"prefix\", \"input_text\", \"target_text\"])\n",
        "\n",
        "\n",
        "    data = []\n",
        "    for src, trg in zip(X_test, y_test):\n",
        "        data.append([f\"translate {src_lang} to {trg_lang}\", src, trg])\n",
        "        #data.append([f\"translate {trg_lang} to {src_lang}\", trg, src])\n",
        "\n",
        "    eval_df = pd.DataFrame(data, columns=[\"prefix\", \"input_text\", \"target_text\"])\n",
        "\n",
        "    return train_df, eval_df\n",
        "    "
      ],
      "metadata": {
        "id": "DEYVNQ8TgPnv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}